// src/hooks/useFaceMonitor.js
import { useEffect, useRef, useState } from "react";
import * as faceapi from "face-api.js";

// Frases de ausÃªncia (sem rosto)
const ABSENCE_MSGS = [
  "NÃ£o consigo te ver.",
  "OlÃ¡, tem certeza de que vocÃª estÃ¡ aÃ­?",
  "Poxa! Acho que nÃ£o estÃ¡ enquadrado na cÃ¢mera."
];

// Frases de silÃªncio com mic desligado
const NO_MIC_MSGS = [
  "Acho que vocÃª esqueceu de abrir o microfone.",
  "Se nÃ£o puder falar, fique Ã  vontade para digitar no chat sua resposta.",
  "EstÃ¡ tudo bem? Estou no aguardo da sua resposta."
];

// Frases de silÃªncio com mic ligado
const SILENT_MIC_MSGS = [
  "NÃ£o consigo te ouvir...",
  "Certeza que seu microfone estÃ¡ funcionando?",
  "VocÃª estÃ¡ falando algo? NÃ£o consigo ouvir nada..."
];

export function useFaceMonitor(
  videoRef,
  camOn,
  interviewStarted,
  playTTS,
  micOn,
  transcript,
  awaitingResponse
) {
  const [userVisible, setUserVisible] = useState(true);
  const absenceIdxRef = useRef(0);
  const absenceTimerRef = useRef(null);
  const silenceTimerRef = useRef(null);
  const lastTranscriptRef = useRef("");

  useEffect(() => {
    if (!interviewStarted || !camOn || !videoRef.current) return;

    faceapi.nets.tinyFaceDetector.loadFromUri("/models").catch(console.error);
    let canceled = false;

    const detectLoop = async () => {
      if (canceled) return;

      try {
        const detection = await faceapi.detectSingleFace(
          videoRef.current,
          new faceapi.TinyFaceDetectorOptions()
        );

        if (detection) {
          // ðŸ‘¤ Rosto detectado
          setUserVisible(true);

          // ðŸ§¹ Limpa timeout de ausÃªncia
          if (absenceTimerRef.current) {
            clearTimeout(absenceTimerRef.current);
            absenceTimerRef.current = null;
          }

          // ðŸ¤ Monitoramento de silÃªncio
          if (awaitingResponse) {
            const trimmed = transcript.trim();

            if (trimmed === lastTranscriptRef.current) {
              // EstÃ¡ parado
              if (!silenceTimerRef.current) {
                console.log("[SILÃŠNCIO] Iniciando timer...", { micOn, transcript });
                silenceTimerRef.current = setTimeout(async () => {
                  if (!videoRef.current || canceled) return;

                  const msgs = micOn ? SILENT_MIC_MSGS : NO_MIC_MSGS;
                  const random = Math.floor(Math.random() * msgs.length);
                  console.log("[SILÃŠNCIO] Falando:", msgs[random]);
                  await playTTS(msgs[random]);

                  silenceTimerRef.current = null;
                }, 5000);
              }
            } else {
              // O usuÃ¡rio falou ou digitou
              lastTranscriptRef.current = trimmed;
              if (silenceTimerRef.current) {
                clearTimeout(silenceTimerRef.current);
                silenceTimerRef.current = null;
                console.log("[SILÃŠNCIO] Cancelado â€” houve transcriÃ§Ã£o.");
              }
            }
          } else {
            // nÃ£o estÃ¡ aguardando resposta â†’ limpa
            if (silenceTimerRef.current) {
              clearTimeout(silenceTimerRef.current);
              silenceTimerRef.current = null;
            }
          }

        } else {
          // ðŸš¶â€â™‚ï¸ Rosto ausente
          setUserVisible(false);

          if (!absenceTimerRef.current) {
            absenceTimerRef.current = setTimeout(async () => {
              if (!videoRef.current || canceled) return;

              const next = (absenceIdxRef.current + 1) % ABSENCE_MSGS.length;
              absenceIdxRef.current = next;
              await playTTS(ABSENCE_MSGS[next]);

              absenceTimerRef.current = null;
            }, 3000);
          }

          // cancela silÃªncio se sumiu
          if (silenceTimerRef.current) {
            clearTimeout(silenceTimerRef.current);
            silenceTimerRef.current = null;
          }
        }

      } catch (err) {
        console.error("Face detect error:", err);
      }

      requestAnimationFrame(detectLoop);
    };

    const handlePlaying = () => detectLoop();
    if (videoRef.current.readyState >= 3) handlePlaying();
    videoRef.current.addEventListener("playing", handlePlaying);

    return () => {
      canceled = true;
      videoRef.current.removeEventListener("playing", handlePlaying);
      setUserVisible(true);
      if (absenceTimerRef.current) clearTimeout(absenceTimerRef.current);
      if (silenceTimerRef.current) clearTimeout(silenceTimerRef.current);
    };
  }, [interviewStarted, camOn, transcript, micOn, awaitingResponse]);

  return { userVisible };
}
